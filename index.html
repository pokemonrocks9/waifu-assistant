<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="theme-color" content="#1a1a2e">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="manifest" href="manifest.json">
    <title>AI Assistant Pod</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            overflow: hidden;
            position: fixed;
            width: 100%;
            height: 100%;
        }

        #canvas-container {
            width: 100%;
            height: 100%;
            position: relative;
            touch-action: none;
        }

        #loading {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: white;
            font-size: 20px;
            text-align: center;
            z-index: 10;
        }

        .spinner {
            border: 4px solid rgba(255, 255, 255, 0.1);
            border-radius: 50%;
            border-top: 4px solid #00d4ff;
            width: 50px;
            height: 50px;
            animation: spin 1s linear infinite;
            margin: 0 auto 20px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        #controls {
            position: absolute;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0, 0, 0, 0.7);
            padding: 15px 25px;
            border-radius: 25px;
            color: white;
            font-size: 14px;
            backdrop-filter: blur(10px);
            z-index: 5;
        }

        /* ========== TEMPORARY TEXT INPUT - REMOVE WHEN MICROPHONE ADDED ========== */
        /* This is a placeholder for testing TTS and lip-sync */
        /* Will be replaced with microphone button in future phase */
        #text-input-container {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            width: 90%;
            max-width: 600px;
            display: flex;
            gap: 10px;
            z-index: 10;
        }

        #text-input {
            flex: 1;
            background: rgba(20, 20, 40, 0.95);
            border: 2px solid rgba(255, 255, 255, 0.3);
            border-radius: 25px;
            padding: 15px 20px;
            color: white;
            font-size: 16px;
            outline: none;
            backdrop-filter: blur(10px);
        }

        #text-input:focus {
            border-color: #00d4ff;
        }

        #text-input::placeholder {
            color: rgba(255, 255, 255, 0.5);
        }

        #speak-btn {
            background: rgba(0, 212, 255, 0.8);
            border: none;
            border-radius: 25px;
            padding: 15px 30px;
            color: white;
            font-size: 16px;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s;
            backdrop-filter: blur(10px);
        }

        #speak-btn:hover {
            background: rgba(0, 212, 255, 1);
            transform: scale(1.05);
        }

        #speak-btn:disabled {
            background: rgba(100, 100, 100, 0.5);
            cursor: not-allowed;
            transform: scale(1);
        }

        #speak-btn.speaking {
            background: rgba(255, 100, 100, 0.8);
        }

        #text-input:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            border-color: rgba(100, 100, 100, 0.3);
        }
        /* ======================================================================== */

        /* Character Selector Menu */
        #character-menu {
            position: fixed;
            right: -320px; /* Hidden off-screen */
            top: 0;
            width: 300px;
            height: 100%;
            background: rgba(20, 20, 40, 0.95);
            backdrop-filter: blur(10px);
            transition: right 0.3s ease;
            z-index: 100;
            overflow-y: auto;
            padding: 20px;
            box-shadow: -5px 0 20px rgba(0, 0, 0, 0.5);
        }

        #character-menu.open {
            right: 0; /* Slide in */
        }

        #character-menu h2 {
            color: #00d4ff;
            margin: 0 0 20px 0;
            font-size: 24px;
            text-align: center;
        }

        .character-item {
            background: rgba(255, 255, 255, 0.1);
            border: 2px solid rgba(255, 255, 255, 0.2);
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 15px;
            cursor: pointer;
            transition: all 0.2s;
            display: flex;
            align-items: center;
            gap: 15px;
        }

        .character-item:hover {
            background: rgba(255, 255, 255, 0.2);
            border-color: #00d4ff;
            transform: translateX(-5px);
        }

        .character-item.active {
            background: rgba(0, 212, 255, 0.3);
            border-color: #00d4ff;
        }

        .character-thumb {
            width: 60px;
            height: 60px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 8px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 30px;
        }

        .character-info {
            flex: 1;
            min-width: 0; /* Allow text to shrink */
        }

        .character-name {
            color: white;
            font-size: 16px;
            font-weight: bold;
            margin-bottom: 5px;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }

        .character-desc {
            color: rgba(255, 255, 255, 0.7);
            font-size: 12px;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }

        /* Tutorial hint - shows on first load */
        #tutorial-hint {
            position: fixed;
            right: 10px;
            top: 50%;
            transform: translateY(-50%);
            background: rgba(0, 212, 255, 0.9);
            color: white;
            padding: 30px 12px;
            border-radius: 10px;
            font-size: 14px;
            z-index: 150;
            animation: slideInRight 0.5s ease, fadeOut 0.5s ease 4.5s forwards;
            pointer-events: none;
            box-shadow: 0 4px 15px rgba(0, 212, 255, 0.4);
            writing-mode: vertical-rl;
            text-orientation: mixed;
            letter-spacing: 2px;
        }

        @keyframes slideInRight {
            from {
                right: -100px;
                opacity: 0;
            }
            to {
                right: 10px;
                opacity: 1;
            }
        }

        @keyframes fadeOut {
            to {
                opacity: 0;
                right: -100px;
            }
        }

        /* Desktop-only menu button */
        #desktop-menu-btn {
            display: none; /* Hidden on mobile */
            position: fixed;
            top: 20px;
            right: 20px;
            background: transparent;
            color: white;
            border: 2px solid rgba(255, 255, 255, 0.5);
            padding: 10px 15px;
            border-radius: 8px;
            font-size: 24px;
            cursor: pointer;
            z-index: 50;
            transition: all 0.3s;
            backdrop-filter: blur(5px);
            line-height: 1;
        }

        #desktop-menu-btn:hover {
            background: rgba(255, 255, 255, 0.1);
            border-color: rgba(255, 255, 255, 0.8);
            transform: scale(1.05);
        }

        #desktop-menu-btn::before {
            content: '☰';
        }

        /* Show button only on desktop (>768px width) */
        @media (min-width: 768px) {
            #desktop-menu-btn {
                display: block;
            }
            #tutorial-hint {
                display: none; /* Don't show tutorial on desktop */
            }
        }

        #error {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background: rgba(255, 0, 0, 0.8);
            color: white;
            padding: 20px;
            border-radius: 10px;
            display: none;
            max-width: 80%;
            text-align: center;
            z-index: 20;
        }

        canvas {
            display: block;
            width: 100%;
            height: 100%;
        }
    </style>
</head>
<body>
    <div id="canvas-container"></div>
    
    <div id="loading">
        <div class="spinner"></div>
        <div>Loading VRM Model...</div>
    </div>

    <div id="error"></div>

    <!-- ========== TEMPORARY TEXT INPUT - REMOVE WHEN MICROPHONE ADDED ========== -->
    <!-- This is for testing TTS and lip-sync before implementing voice input -->
    <div id="text-input-container">
        <input type="text" id="text-input" placeholder="Type something for her to say..." />
        <button id="speak-btn">Send</button>
    </div>
    <!-- ======================================================================== -->

    <div id="controls" style="display: none;">
        Idle Animation Active
    </div>

    <!-- Tutorial hint - shows on first load (mobile only) -->
    <div id="tutorial-hint">
        Swipe
    </div>

    <!-- Desktop menu button (desktop only) -->
    <button id="desktop-menu-btn"></button>

    <!-- Character Selector Menu -->
    <div id="character-menu">
        <h2>Characters</h2>
        <div id="character-list">
            <!-- Characters will be populated by JavaScript -->
        </div>
    </div>

    <!-- Three.js and VRM Libraries -->
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.169.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.169.0/examples/jsm/",
                "@pixiv/three-vrm": "https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3.1.6/lib/three-vrm.module.js"
            }
        }
    </script>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';

        let scene, camera, renderer, controls, currentVrm;
        const container = document.getElementById('canvas-container');
        const loadingDiv = document.getElementById('loading');
        const errorDiv = document.getElementById('error');

        // ============ CHARACTER LIST - ADD YOUR CHARACTERS HERE ============
        const characters = [
            {
                id: 'default',
                name: 'Sample Character',
                description: 'Default VRM model',
                emoji: '👾',
                url: 'https://pixiv.github.io/three-vrm/packages/three-vrm/examples/models/VRM1_Constraint_Twist_Sample.vrm'
            },
            // Add more characters here - name/description will be auto-loaded from VRM metadata:
            // {
            //     id: 'character2',
            //     name: 'Loading...',  // Will be replaced with VRM metadata
            //     description: 'Custom character',
            //     emoji: '🎀',
            //     url: './models/your-character.vrm'
            // },
        ];
        let currentCharacterId = 'default';
        let characterMetadataLoaded = false;
        // ====================================================================

        // Menu state
        let menuOpen = false;
        let touchStartX = 0;
        let touchStartY = 0;

        // Animation variables
        let clock = new THREE.Clock();
        let idleAnimation = {
            // === ANIMATION SETTINGS - EDIT THESE TO CUSTOMIZE ===
            breathingSpeed: 2.0,      // How fast breathing cycles (higher = faster)
            breathingAmount: 0.01,    // How much chest moves (higher = more movement)
            blinkTimer: 0,
            blinkInterval: 3.0,       // Seconds between blinks (higher = less frequent)
            isBlinking: false,
            blinkDuration: 0.15       // How long blink takes (higher = slower blink)
            // ===================================================
        };

        // Cursor/Look-at tracking
        let mousePosition = { x: 0, y: 0 };
        let targetLookAt = { x: 0, y: 0 };
        let currentLookAt = { x: 0, y: 0 };
        const lookAtSpeed = 0.05; // How fast head follows cursor (lower = smoother)
        let lookAtTarget = null; // THREE.Object3D for VRM lookAt system

        // ========== TEXT-TO-SPEECH AND LIP-SYNC ==========
        // NOTE: This will be replaced with microphone input later
        // TODO: When moving from GitHub Pages to homelab hosting:
        //   1. Replace browser TTS with Coqui TTS or Piper on homelab server
        //   2. Set up Python FastAPI backend on homelab
        //   3. Stream audio from server via WebSocket
        //   4. Benefits: Natural voices, consistent across devices, customizable
        //   5. Recommended: Coqui TTS (tts_models/en/vctk/vits) or Piper for speed
        // TODO: Add voice selector in settings menu:
        //   - Dropdown with cute/soft voice options (see VOICE_OPTIONS.md)
        //   - Voices: en_US-lessac-medium, en_US-amy-medium, en_GB-jenny_dioco-medium
        //   - Test button to preview each voice
        //   - Save selection to localStorage
        //   - Pass selected voice to backend TTS endpoint
        
        // Backend connection settings
        const BACKEND_URL = 'wss://waifubackend.pokymedia.xyz/ws'; // WebSocket
        const BACKEND_API = 'https://waifubackend.pokymedia.xyz'; // HTTP API
        let ws = null;
        let isConnectedToBackend = false;
        
        let isSpeaking = false;
        let audioContext = null;
        let audioAnalyser = null;
        let audioDataArray = null;
        let audioSource = null;
        let currentUtterance = null;
        let lipSyncInterval = null;
        // =================================================

        function init() {
            // Scene setup
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0x1a1a2e);

            // ============ CAMERA SETUP - EDIT FOR DIFFERENT VIEW ============
            // Camera setup - adjusted for portrait mobile view
            camera = new THREE.PerspectiveCamera(
                35,  // Field of view (higher = wider view, lower = zoomed in)
                window.innerWidth / window.innerHeight,
                0.1,
                100
            );
            camera.position.set(0, 1.3, 2.5);  // (x, y, z) - adjust to frame character
            // x: left/right (0 = centered)
            // y: up/down (1.3 = eye level)
            // z: distance from character (2.5 = close portrait, try 3-4 for full body)
            // ================================================================

            // Renderer setup
            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2)); // Optimize for mobile
            renderer.outputColorSpace = THREE.SRGBColorSpace;
            container.appendChild(renderer.domElement);

            // Lighting
            const directionalLight = new THREE.DirectionalLight(0xffffff, 1.5);
            directionalLight.position.set(1, 1, 1);
            scene.add(directionalLight);

            const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
            scene.add(ambientLight);

            // Controls disabled - character will animate on its own
            // controls = new OrbitControls(camera, renderer.domElement);
            // controls.enableDamping = true;
            // controls.dampingFactor = 0.05;
            // controls.target.set(0, 1.2, 0);
            // controls.minDistance = 1;
            // controls.maxDistance = 5;
            // controls.enablePan = false;
            // controls.update();

            // Handle window resize
            window.addEventListener('resize', onWindowResize);

            // Initialize character menu
            initCharacterMenu();
            setupSwipeDetection();
            setupCursorTracking();
            setupTextToSpeech(); // TEMPORARY - for testing lip-sync

            // Load VRM model
            loadVRM();

            // Start animation loop
            animate();
        }

        // ============ BACKEND CONNECTION FUNCTIONS ============
        
        let pendingResponseText = ''; // Store text for lip-sync
        
        function connectToBackend() {
            console.log('Connecting to backend:', BACKEND_URL);
            
            ws = new WebSocket(BACKEND_URL);
            
            ws.onopen = () => {
                console.log('Connected to backend!');
                isConnectedToBackend = true;
                updateConnectionStatus('Connected');
            };
            
            ws.onmessage = async (event) => {
                const data = JSON.parse(event.data);
                console.log('Received from backend:', data);
                
                if (data.type === 'connected') {
                    console.log('Backend welcome:', data.message);
                } else if (data.type === 'response') {
                    // Store the text for lip-sync when audio arrives
                    pendingResponseText = data.text;
                    
                    // Got AI response - request TTS via WebSocket
                    ws.send(JSON.stringify({
                        type: 'tts',
                        text: data.text
                    }));
                } else if (data.type === 'audio') {
                    // Received audio data as base64 - use stored text for lip-sync
                    await playAudioFromBase64(data.data, pendingResponseText);
                    pendingResponseText = ''; // Clear after use
                } else if (data.type === 'error') {
                    console.error('Backend error:', data.text);
                    // Fallback to browser TTS
                    speak(data.text);
                }
            };
            
            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
                isConnectedToBackend = false;
                updateConnectionStatus('Error');
            };
            
            ws.onclose = () => {
                console.log('Disconnected from backend');
                isConnectedToBackend = false;
                updateConnectionStatus('Disconnected');
                
                // Try to reconnect after 5 seconds
                setTimeout(() => {
                    console.log('Attempting to reconnect...');
                    connectToBackend();
                }, 5000);
            };
        }
        
        function sendMessageToBackend(text) {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({
                    type: 'message',
                    text: text
                }));
                return true;
            } else {
                console.error('WebSocket not connected');
                return false;
            }
        }
        
        async function speakWithBackend(text) {
            console.log('Speaking with backend TTS:', text);
            isSpeaking = true;
            const speakBtn = document.getElementById('speak-btn');
            const textInput = document.getElementById('text-input');
            speakBtn.classList.add('speaking');
            speakBtn.textContent = 'Speaking...';
            
            try {
                // Get audio from backend
                const response = await fetch(`${BACKEND_API}/api/tts`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ text: text })
                });
                
                if (response.ok) {
                    const audioBlob = await response.blob();
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audio = new Audio(audioUrl);
                    
                    // Start lip-sync when audio starts
                    audio.onplay = () => {
                        startLipSync(text);
                    };
                    
                    audio.onended = () => {
                        isSpeaking = false;
                        speakBtn.classList.remove('speaking');
                        speakBtn.textContent = 'Send';
                        speakBtn.disabled = false;
                        textInput.disabled = false;
                        textInput.focus();
                        stopLipSync();
                        URL.revokeObjectURL(audioUrl);
                    };
                    
                    audio.onerror = (e) => {
                        console.error('Audio playback error:', e);
                        stopLipSync();
                        isSpeaking = false;
                        speakBtn.classList.remove('speaking');
                        speakBtn.textContent = 'Send';
                        speakBtn.disabled = false;
                        textInput.disabled = false;
                        textInput.focus();
                    };
                    
                    await audio.play();
                } else {
                    console.error('TTS request failed:', response.status);
                    // Fallback to browser TTS
                    speak(text);
                }
            } catch (error) {
                console.error('Backend TTS error:', error);
                // Fallback to browser TTS
                speak(text);
            }
        }
        
        async function playAudioFromBase64(base64Audio, text) {
            console.log('Playing audio from WebSocket');
            isSpeaking = true;
            const speakBtn = document.getElementById('speak-btn');
            const textInput = document.getElementById('text-input');
            speakBtn.classList.add('speaking');
            speakBtn.textContent = 'Speaking...';
            
            try {
                // Convert base64 to blob
                const binaryString = atob(base64Audio);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                const audioBlob = new Blob([bytes], { type: 'audio/wav' });
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                
                // START LIP-SYNC IMMEDIATELY - before audio plays
                console.log('Starting lip-sync for:', text);
                startLipSync(text);
                
                audio.onended = () => {
                    isSpeaking = false;
                    speakBtn.classList.remove('speaking');
                    speakBtn.textContent = 'Send';
                    speakBtn.disabled = false;
                    textInput.disabled = false;
                    textInput.focus(); // Return focus to input
                    stopLipSync();
                    URL.revokeObjectURL(audioUrl);
                };
                
                audio.onerror = (e) => {
                    console.error('Audio playback error:', e);
                    stopLipSync();
                    isSpeaking = false;
                    speakBtn.classList.remove('speaking');
                    speakBtn.textContent = 'Send';
                    speakBtn.disabled = false;
                    textInput.disabled = false;
                    textInput.focus();
                };
                
                await audio.play();
            } catch (error) {
                console.error('Audio playback error:', error);
                stopLipSync();
                isSpeaking = false;
                const speakBtn = document.getElementById('speak-btn');
                const textInput = document.getElementById('text-input');
                speakBtn.classList.remove('speaking');
                speakBtn.textContent = 'Send';
                speakBtn.disabled = false;
                textInput.disabled = false;
                textInput.focus();
            }
        }
        
        function updateConnectionStatus(status) {
            // You can add a status indicator in the UI later
            console.log('Connection status:', status);
        }
        
        // =======================================================

        // ============ TEXT-TO-SPEECH AND LIP-SYNC FUNCTIONS ============
        // NOTE: This is TEMPORARY for testing - will be replaced with microphone input
        
        function setupTextToSpeech() {
            const textInput = document.getElementById('text-input');
            const speakBtn = document.getElementById('speak-btn');

            // Initialize Web Audio API for lip-sync
            audioContext = new (window.AudioContext || window.webkitAudioContext)();

            // Connect to backend
            connectToBackend();

            // Speak button click
            speakBtn.addEventListener('click', () => {
                const text = textInput.value.trim();
                if (text && !isSpeaking) {
                    // Clear input and disable controls
                    textInput.value = '';
                    textInput.disabled = true;
                    speakBtn.disabled = true;
                    
                    if (isConnectedToBackend) {
                        // Send to backend for AI response
                        sendMessageToBackend(text);
                    } else {
                        // Fallback to local TTS
                        speak(text);
                    }
                }
            });

            // Enter key to speak
            textInput.addEventListener('keypress', (e) => {
                if (e.key === 'Enter') {
                    const text = textInput.value.trim();
                    if (text && !isSpeaking) {
                        // Clear input and disable controls
                        textInput.value = '';
                        textInput.disabled = true;
                        speakBtn.disabled = true;
                        
                        if (isConnectedToBackend) {
                            sendMessageToBackend(text);
                        } else {
                            speak(text);
                        }
                    }
                }
            });
        }

        function speak(text) {
            if (isSpeaking) {
                console.log('Already speaking, cancelling...');
                window.speechSynthesis.cancel();
                stopLipSync();
                return;
            }

            console.log('Speaking:', text);
            isSpeaking = true;
            const speakBtn = document.getElementById('speak-btn');
            const textInput = document.getElementById('text-input');
            speakBtn.classList.add('speaking');
            speakBtn.textContent = 'Speaking...';

            // Create speech utterance
            currentUtterance = new SpeechSynthesisUtterance(text);
            
            // Configure voice (try to use a female voice)
            const voices = window.speechSynthesis.getVoices();
            const femaleVoice = voices.find(voice => 
                voice.name.includes('female') || 
                voice.name.includes('Female') ||
                voice.name.includes('Samantha') ||
                voice.name.includes('Victoria') ||
                voice.name.includes('Google UK English Female') ||
                voice.name.includes('Google US English Female')
            );
            if (femaleVoice) {
                currentUtterance.voice = femaleVoice;
            }
            
            currentUtterance.rate = 1.0;
            currentUtterance.pitch = 1.2;

            // Start lip-sync animation
            currentUtterance.onstart = () => {
                console.log('Speech started');
                startLipSync(text);
            };

            currentUtterance.onend = () => {
                console.log('Speech ended');
                stopLipSync();
                // Re-enable input
                speakBtn.disabled = false;
                textInput.disabled = false;
                textInput.focus();
            };

            currentUtterance.onerror = (e) => {
                console.error('Speech error:', e);
                stopLipSync();
                // Re-enable input
                speakBtn.disabled = false;
                textInput.disabled = false;
                textInput.focus();
            };

            window.speechSynthesis.speak(currentUtterance);
        }

        function startLipSync(text) {
            console.log('Starting sophisticated lip-sync for:', text);
            
            // Analyze text for phonemes and create timing
            const phonemeTimings = analyzeTextForPhonemes(text);
            let phonemeIndex = 0;
            const startTime = Date.now();

            // Update mouth shapes based on phoneme timing
            lipSyncInterval = setInterval(() => {
                if (!isSpeaking) {
                    clearInterval(lipSyncInterval);
                    return;
                }

                const elapsed = Date.now() - startTime;
                
                // Find current phoneme
                while (phonemeIndex < phonemeTimings.length && 
                       phonemeTimings[phonemeIndex].time < elapsed) {
                    phonemeIndex++;
                }

                if (phonemeIndex < phonemeTimings.length) {
                    const phoneme = phonemeTimings[phonemeIndex];
                    setMouthShape(phoneme.shape, phoneme.amount);
                } else {
                    // End of speech
                    setMouthShape('closed', 0);
                }
            }, 16); // ~60fps
        }

        function stopLipSync() {
            isSpeaking = false;
            const speakBtn = document.getElementById('speak-btn');
            speakBtn.classList.remove('speaking');
            speakBtn.textContent = 'Send';
            
            if (lipSyncInterval) {
                clearInterval(lipSyncInterval);
                lipSyncInterval = null;
            }
            
            // Close mouth
            setMouthShape('closed', 0);
        }

        function analyzeTextForPhonemes(text) {
            // Analyze text and create phoneme timing estimates
            const words = text.toLowerCase().split(/\s+/);
            const phonemes = [];
            let time = 0;
            const msPerChar = 80; // Approximate timing

            words.forEach((word, wordIndex) => {
                for (let i = 0; i < word.length; i++) {
                    const char = word[i];
                    const nextChar = word[i + 1] || '';
                    
                    // Map characters to mouth shapes
                    let shape = 'closed';
                    let amount = 0.5;

                    // Vowels - open mouth shapes
                    if ('aā'.includes(char)) {
                        shape = 'aa'; // Wide open
                        amount = 0.8;
                    } else if ('eē'.includes(char)) {
                        shape = 'ee'; // Smile
                        amount = 0.6;
                    } else if ('iī'.includes(char)) {
                        shape = 'ih'; // Small open
                        amount = 0.5;
                    } else if ('oōuū'.includes(char)) {
                        shape = 'ou'; // Round
                        amount = 0.7;
                    }
                    // Consonants
                    else if ('bpm'.includes(char)) {
                        shape = 'closed'; // Lips together
                        amount = 0.1;
                    } else if ('fv'.includes(char)) {
                        shape = 'ff'; // Lip bite
                        amount = 0.4;
                    } else if ('td'.includes(char)) {
                        shape = 'dd'; // Teeth
                        amount = 0.3;
                    } else if ('szcx'.includes(char)) {
                        shape = 'ss'; // Hiss
                        amount = 0.3;
                    } else if ('lnr'.includes(char)) {
                        shape = 'aa'; // Slight open
                        amount = 0.4;
                    }

                    phonemes.push({
                        char: char,
                        shape: shape,
                        amount: amount,
                        time: time
                    });

                    time += msPerChar;
                }

                // Add pause between words
                phonemes.push({
                    char: ' ',
                    shape: 'closed',
                    amount: 0,
                    time: time
                });
                time += msPerChar * 0.5;
            });

            return phonemes;
        }

        function setMouthShape(shape, amount) {
            if (!currentVrm || !currentVrm.expressionManager) return;

            try {
                // Reset all mouth shapes
                const allShapes = ['aa', 'ih', 'ou', 'ee', 'oh', 'a', 'i', 'u', 'e', 'o'];
                allShapes.forEach(s => {
                    try {
                        currentVrm.expressionManager.setValue(s, 0);
                    } catch (e) {}
                });

                // Set target shape
                if (shape !== 'closed') {
                    const shapeVariants = [shape, shape.toUpperCase()];
                    for (const variant of shapeVariants) {
                        try {
                            currentVrm.expressionManager.setValue(variant, amount);
                            break;
                        } catch (e) {}
                    }
                }
            } catch (error) {
                // Expressions not available
            }
        }

        function updateLipSync() {
            // Lip-sync is now handled by interval in startLipSync
            // This function kept for compatibility but not used
        }

        // Load voices when they're ready
        if (typeof speechSynthesis !== 'undefined') {
            speechSynthesis.onvoiceschanged = () => {
                console.log('Voices loaded:', speechSynthesis.getVoices().length);
            };
        }
        // ================================================================

        // ============ CURSOR TRACKING FUNCTIONS ============
        function setupCursorTracking() {
            // Mouse movement
            document.addEventListener('mousemove', (e) => {
                // Convert mouse position to normalized coordinates (-1 to 1)
                mousePosition.x = (e.clientX / window.innerWidth) * 2 - 1;
                mousePosition.y = -(e.clientY / window.innerHeight) * 2 + 1;
                
                // Set target look position
                targetLookAt.x = mousePosition.x * 0.5; // Reduce range for natural movement
                targetLookAt.y = mousePosition.y * 0.3;
            });

            // Touch movement (mobile)
            document.addEventListener('touchmove', (e) => {
                if (e.touches[0]) {
                    mousePosition.x = (e.touches[0].clientX / window.innerWidth) * 2 - 1;
                    mousePosition.y = -(e.touches[0].clientY / window.innerHeight) * 2 + 1;
                    
                    targetLookAt.x = mousePosition.x * 0.5;
                    targetLookAt.y = mousePosition.y * 0.3;
                }
            }, { passive: true });
        }

        function updateCursorTracking() {
            if (!currentVrm || !currentVrm.humanoid) return;

            try {
                // Smooth interpolation to target
                currentLookAt.x += (targetLookAt.x - currentLookAt.x) * lookAtSpeed;
                currentLookAt.y += (targetLookAt.y - currentLookAt.y) * lookAtSpeed;

                // Get head and neck bones
                const head = currentVrm.humanoid.getNormalizedBoneNode('head');
                const neck = currentVrm.humanoid.getNormalizedBoneNode('neck');
                
                // Rotate head to look at cursor
                if (head) {
                    head.rotation.y = currentLookAt.x * 0.7; // Left/right
                    head.rotation.x = -currentLookAt.y * 0.5; // Up/down (inverted)
                }
                
                // Subtle neck movement
                if (neck) {
                    neck.rotation.y = currentLookAt.x * 0.3;
                    neck.rotation.x = -currentLookAt.y * 0.2; // Up/down (inverted)
                }

                // Manual eye control (works for both VRM 0.x and 1.0)
                const leftEye = currentVrm.humanoid.getNormalizedBoneNode('leftEye');
                const rightEye = currentVrm.humanoid.getNormalizedBoneNode('rightEye');
                
                if (leftEye) {
                    leftEye.rotation.y = currentLookAt.x * 0.4;
                    leftEye.rotation.x = -currentLookAt.y * 0.3;
                }
                if (rightEye) {
                    rightEye.rotation.y = currentLookAt.x * 0.4;
                    rightEye.rotation.x = -currentLookAt.y * 0.3;
                }
            } catch (error) {
                console.error('Error in cursor tracking:', error);
            }
        }
        // ==================================================

        // ============ CHARACTER MENU FUNCTIONS ============
        async function loadCharacterMetadata() {
            console.log('Loading character metadata from VRM files...');
            
            for (let i = 0; i < characters.length; i++) {
                const char = characters[i];
                
                try {
                    const response = await fetch(char.url);
                    if (!response.ok) continue;
                    
                    const blob = await response.blob();
                    const blobUrl = URL.createObjectURL(blob);
                    
                    const loader = new GLTFLoader();
                    loader.register((parser) => new VRMLoaderPlugin(parser));
                    
                    loader.load(
                        blobUrl,
                        (gltf) => {
                            const vrm = gltf.userData.vrm;
                            if (vrm && vrm.meta) {
                                // Update character info with VRM metadata
                                if (vrm.meta.name && vrm.meta.name !== '') {
                                    characters[i].name = vrm.meta.name;
                                }
                                if (vrm.meta.version && vrm.meta.version !== '') {
                                    characters[i].description = `Version: ${vrm.meta.version}`;
                                }
                                if (vrm.meta.author && vrm.meta.author !== '') {
                                    characters[i].description = `By ${vrm.meta.author}`;
                                }
                                
                                console.log(`Loaded metadata for ${char.id}:`, vrm.meta);
                                
                                // Refresh UI if already initialized
                                if (characterMetadataLoaded) {
                                    updateCharacterUI(i);
                                }
                            }
                            URL.revokeObjectURL(blobUrl);
                        },
                        undefined,
                        (error) => {
                            console.log(`Could not load metadata for ${char.id}:`, error);
                            URL.revokeObjectURL(blobUrl);
                        }
                    );
                } catch (error) {
                    console.log(`Error fetching ${char.id}:`, error);
                }
            }
            
            characterMetadataLoaded = true;
        }

        function updateCharacterUI(index) {
            const characterList = document.getElementById('character-list');
            const items = characterList.querySelectorAll('.character-item');
            
            if (items[index]) {
                const char = characters[index];
                items[index].querySelector('.character-name').textContent = char.name;
                items[index].querySelector('.character-desc').textContent = char.description;
            }
        }

        function initCharacterMenu() {
            const characterList = document.getElementById('character-list');
            const menu = document.getElementById('character-menu');
            const desktopBtn = document.getElementById('desktop-menu-btn');
            const tutorialHint = document.getElementById('tutorial-hint');

            // Desktop button click handler
            if (desktopBtn) {
                console.log('Desktop button found, adding click listener');
                desktopBtn.addEventListener('click', (e) => {
                    e.stopPropagation(); // Prevent other handlers
                    console.log('Desktop button clicked!');
                    toggleMenu();
                });
            } else {
                console.log('Desktop button NOT found');
            }

            // Auto-remove tutorial hint after 5 seconds
            if (tutorialHint) {
                setTimeout(() => {
                    tutorialHint.remove();
                }, 5000);
            }

            // Populate character list
            characters.forEach(char => {
                const item = document.createElement('div');
                item.className = 'character-item';
                if (char.id === currentCharacterId) {
                    item.classList.add('active');
                }
                
                item.innerHTML = `
                    <div class="character-thumb">${char.emoji}</div>
                    <div class="character-info">
                        <div class="character-name">${char.name}</div>
                        <div class="character-desc">${char.description}</div>
                    </div>
                `;
                
                item.addEventListener('click', () => {
                    selectCharacter(char.id);
                });
                
                characterList.appendChild(item);
            });

            // Click outside menu to close
            document.addEventListener('click', (e) => {
                const clickedBtn = e.target.id === 'desktop-menu-btn' || e.target.closest('#desktop-menu-btn');
                if (menuOpen && !menu.contains(e.target) && !clickedBtn) {
                    toggleMenu();
                }
            });

            // Load VRM metadata in background
            loadCharacterMetadata();
        }

        function setupSwipeDetection() {
            const menu = document.getElementById('character-menu');
            const swipeHint = document.getElementById('swipe-hint');
            
            // Touch events for swipe
            document.addEventListener('touchstart', (e) => {
                touchStartX = e.touches[0].clientX;
                touchStartY = e.touches[0].clientY;
            }, { passive: true });

            document.addEventListener('touchmove', (e) => {
                // Only prevent default scrolling when swiping from edge, not everywhere
                if (touchStartX > window.innerWidth - 80 && !menuOpen) {
                    e.preventDefault();
                }
            }, { passive: false });

            document.addEventListener('touchend', (e) => {
                if (!e.changedTouches[0]) return;
                
                const touchEndX = e.changedTouches[0].clientX;
                const touchEndY = e.changedTouches[0].clientY;
                const diffX = touchStartX - touchEndX;
                const diffY = Math.abs(touchStartY - touchEndY);

                console.log('Swipe detected:', { touchStartX, touchEndX, diffX, diffY, menuOpen });

                // Swipe left from right edge to open (more lenient detection)
                if (!menuOpen && touchStartX > window.innerWidth - 80 && diffX > 30 && diffY < 150) {
                    console.log('Opening menu via swipe');
                    toggleMenu();
                }
                // Swipe right to close
                else if (menuOpen && diffX < -30 && diffY < 150) {
                    console.log('Closing menu via swipe');
                    toggleMenu();
                }
            }, { passive: true });

            // Mouse drag for desktop testing
            let mouseStartX = 0;
            let isDragging = false;

            document.addEventListener('mousedown', (e) => {
                mouseStartX = e.clientX;
                isDragging = true;
            });

            document.addEventListener('mousemove', (e) => {
                if (!isDragging) return;
                // Visual feedback while dragging from edge
                if (mouseStartX > window.innerWidth - 80) {
                    e.preventDefault();
                }
            });

            document.addEventListener('mouseup', (e) => {
                if (!isDragging) return;
                isDragging = false;
                
                const diffX = mouseStartX - e.clientX;
                
                console.log('Mouse drag:', { mouseStartX, clientX: e.clientX, diffX, menuOpen });
                
                // Drag from right edge to open
                if (!menuOpen && mouseStartX > window.innerWidth - 80 && diffX > 30) {
                    console.log('Opening menu via drag');
                    toggleMenu();
                }
                // Drag right to close
                else if (menuOpen && diffX < -30) {
                    console.log('Closing menu via drag');
                    toggleMenu();
                }
            });
        }

        function toggleMenu() {
            const menu = document.getElementById('character-menu');
            
            menuOpen = !menuOpen;
            
            console.log('toggleMenu called, menuOpen:', menuOpen);
            
            if (menuOpen) {
                menu.classList.add('open');
            } else {
                menu.classList.remove('open');
            }
        }

        function selectCharacter(characterId) {
            if (characterId === currentCharacterId) {
                toggleMenu();
                return;
            }

            currentCharacterId = characterId;
            
            // Update active state in UI
            document.querySelectorAll('.character-item').forEach((item, index) => {
                if (characters[index].id === characterId) {
                    item.classList.add('active');
                } else {
                    item.classList.remove('active');
                }
            });

            // Show loading and load new character
            loadingDiv.style.display = 'block';
            loadingDiv.querySelector('div:last-child').textContent = 'Loading new character...';
            
            loadVRM();
            toggleMenu();
        }
        // ================================================

        async function loadVRM() {
            try {
                // Get the selected character's URL
                const selectedCharacter = characters.find(c => c.id === currentCharacterId);
                const modelUrl = selectedCharacter ? selectedCharacter.url : characters[0].url;

                loadingDiv.querySelector('div:last-child').textContent = 'Downloading model...';

                // Fetch the VRM file as a blob to avoid CORS issues
                const response = await fetch(modelUrl);
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }

                const blob = await response.blob();
                const blobUrl = URL.createObjectURL(blob);

                loadingDiv.querySelector('div:last-child').textContent = 'Loading VRM...';

                // Load the VRM from the blob URL
                const loader = new GLTFLoader();
                loader.register((parser) => {
                    return new VRMLoaderPlugin(parser);
                });

                loader.load(
                    blobUrl,
                    (gltf) => {
                        const vrm = gltf.userData.vrm;

                        if (vrm) {
                            // Remove previous VRM if exists
                            if (currentVrm) {
                                scene.remove(currentVrm.scene);
                                VRMUtils.deepDispose(currentVrm.scene);
                            }

                            currentVrm = vrm;

                            // Disable VRM's built-in lookAt to prevent conflicts with manual tracking
                            if (vrm.lookAt) {
                                vrm.lookAt.target = null;
                            }

                            // Face the camera (no rotation needed - default is facing forward)
                            vrm.scene.rotation.y = 0;

                            // Position character
                            vrm.scene.position.set(0, 0, 0);

                            scene.add(vrm.scene);

                            // Initialize idle animation
                            initIdleAnimation();

                            // Hide loading indicator
                            loadingDiv.style.display = 'none';

                            console.log('VRM model loaded successfully!');
                        }

                        // Clean up blob URL
                        URL.revokeObjectURL(blobUrl);
                    },
                    (progress) => {
                        const percent = (progress.loaded / progress.total * 100).toFixed(0);
                        loadingDiv.querySelector('div:last-child').textContent = `Processing... ${percent}%`;
                    },
                    (error) => {
                        console.error('Error loading VRM:', error);
                        loadingDiv.style.display = 'none';
                        errorDiv.style.display = 'block';
                        errorDiv.textContent = 'Failed to load model. Check console for details.';
                        URL.revokeObjectURL(blobUrl);
                    }
                );
            } catch (error) {
                console.error('Error fetching VRM:', error);
                loadingDiv.style.display = 'none';
                errorDiv.style.display = 'block';
                errorDiv.textContent = `Failed to download model: ${error.message}`;
            }
        }

        function initIdleAnimation() {
            if (!currentVrm) return;
            
            console.log('Idle animation initialized');
            idleAnimation.blinkTimer = Math.random() * idleAnimation.blinkInterval;

            // Set natural standing pose (fix T-pose)
            setNaturalPose();
        }

        function setNaturalPose() {
            if (!currentVrm || !currentVrm.humanoid) return;

            // Get bone references
            const leftUpperArm = currentVrm.humanoid.getNormalizedBoneNode('leftUpperArm');
            const rightUpperArm = currentVrm.humanoid.getNormalizedBoneNode('rightUpperArm');
            const leftLowerArm = currentVrm.humanoid.getNormalizedBoneNode('leftLowerArm');
            const rightLowerArm = currentVrm.humanoid.getNormalizedBoneNode('rightLowerArm');
            const leftHand = currentVrm.humanoid.getNormalizedBoneNode('leftHand');
            const rightHand = currentVrm.humanoid.getNormalizedBoneNode('rightHand');

            // ============ POSE CUSTOMIZATION - EDIT VALUES HERE ============
            
            // UPPER ARMS (shoulder to elbow)
            // rotation.z: controls up/down movement (higher value = further down)
            //   - Left arm: negative values lower arm, positive raises it
            //   - Right arm: positive values lower arm, negative raises it
            // rotation.x: controls forward/back (positive = forward, negative = back)
            if (leftUpperArm) {
                leftUpperArm.rotation.z = -1.4;  // -1.4 = arms at sides (try -1.0 to -2.0)
                leftUpperArm.rotation.x = 0.3;   // 0.3 = slight forward (try 0 to 0.5)
            }
            if (rightUpperArm) {
                rightUpperArm.rotation.z = 1.4;  // Mirror of left arm
                rightUpperArm.rotation.x = 0.3;  // Mirror of left arm
            }

            // LOWER ARMS (elbow to wrist)
            // rotation.y: controls elbow bend (higher = more bent)
            if (leftLowerArm) {
                leftLowerArm.rotation.y = -0.5;  // -0.5 = slight bend (try -0.3 to -0.8)
            }
            if (rightLowerArm) {
                rightLowerArm.rotation.y = 0.5;  // Mirror of left arm
            }

            // HANDS (wrist rotation)
            // rotation.z: controls wrist tilt up/down
            //   - Left hand: negative = tilt down, positive = tilt up
            //   - Right hand: positive = tilt down, negative = tilt up
            if (leftHand) {
                leftHand.rotation.z = -0.2;   // -0.2 = subtle tilt down (try -0.1 to -0.5)
            }
            if (rightHand) {
                rightHand.rotation.z = 0.2;   // Mirror of left hand
            }
            
            // ================================================================

            console.log('Natural pose applied');
        }

        function updateIdleAnimation(deltaTime) {
            if (!currentVrm) return;

            const elapsedTime = clock.getElapsedTime();

            // Breathing animation (chest/spine movement)
            const breathingOffset = Math.sin(elapsedTime * idleAnimation.breathingSpeed) * idleAnimation.breathingAmount;
            if (currentVrm.humanoid) {
                const spine = currentVrm.humanoid.getNormalizedBoneNode('spine');
                const chest = currentVrm.humanoid.getNormalizedBoneNode('chest');
                
                if (spine) {
                    spine.position.y = breathingOffset;
                }
                if (chest) {
                    chest.rotation.x = breathingOffset * 0.5;
                }
            }

            // Blinking animation
            idleAnimation.blinkTimer += deltaTime;
            
            if (!idleAnimation.isBlinking && idleAnimation.blinkTimer >= idleAnimation.blinkInterval) {
                // Start blink
                idleAnimation.isBlinking = true;
                idleAnimation.blinkTimer = 0;
            }

            if (idleAnimation.isBlinking) {
                const blinkProgress = idleAnimation.blinkTimer / idleAnimation.blinkDuration;
                
                if (blinkProgress < 0.5) {
                    // Closing eyes
                    const closeFactor = blinkProgress * 2; // 0 to 1
                    setEyeBlinkValue(closeFactor);
                } else if (blinkProgress < 1.0) {
                    // Opening eyes
                    const openFactor = 1 - ((blinkProgress - 0.5) * 2); // 1 to 0
                    setEyeBlinkValue(openFactor);
                } else {
                    // Blink complete
                    setEyeBlinkValue(0);
                    idleAnimation.isBlinking = false;
                    idleAnimation.blinkTimer = Math.random() * idleAnimation.blinkInterval;
                }
            }
        }

        function setEyeBlinkValue(value) {
            if (!currentVrm || !currentVrm.expressionManager) return;
            
            // Try common blink expression names
            const blinkExpressions = ['blink', 'blinkLeft', 'blinkRight', 'Blink', 'blink_L', 'blink_R'];
            
            for (const expressionName of blinkExpressions) {
                try {
                    currentVrm.expressionManager.setValue(expressionName, value);
                } catch (e) {
                    // Expression might not exist, that's okay
                }
            }
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        function animate() {
            requestAnimationFrame(animate);

            const deltaTime = clock.getDelta();

            // Update cursor tracking
            updateCursorTracking();

            // Update lip-sync (TEMPORARY - for testing)
            updateLipSync();

            // Update idle animation
            updateIdleAnimation(deltaTime);

            // Update VRM if loaded
            if (currentVrm) {
                currentVrm.update(deltaTime);
            }

            // controls.update(); // Removed - no controls anymore
            renderer.render(scene, camera);
        }

        // Start the application
        init();

        // Register service worker for PWA
        if ('serviceWorker' in navigator) {
            window.addEventListener('load', () => {
                navigator.serviceWorker.register('./sw.js')
                    .then((registration) => {
                        console.log('Service Worker registered:', registration);
                    })
                    .catch((error) => {
                        console.log('Service Worker registration failed:', error);
                    });
            });
        }
    </script>
</body>
</html>
